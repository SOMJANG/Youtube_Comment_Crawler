# ğŸ½ Youtube_Comment_Crawler
ìœ íŠœë¸Œ ëŒ“ê¸€ í¬ë¡¤ëŸ¬ ( Python, BeautifulSoup, Selenium )
<p align="center">
  <img width=800 src="./images/youtube_logo.png">
</p>

### ğŸ—ƒ ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
- BeautifulSoup
- Selenium
- pandas
- requests

### ğŸ“ ì°¸ê³  í˜ì´ì§€ - https://bit.ly/2yyl7F5

### ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ë¡¤ëŸ¬ - https://github.com/SOMJANG/Instagram_Crawler

### ğŸ–¥ ì„¸ë¶€ ì„¤ëª…

### ğŸ’» get_urls_from_youtube_with_keyword(keyword) ğŸ’»
- ì›í•˜ëŠ” í‚¤ì›Œë“œì— ëŒ€í•œ ìœ íŠœë¸Œ ì˜ìƒ ì œëª©ê³¼ URLì„ Crawling í•˜ëŠ” í•¨ìˆ˜
- ì—¬ëŸ¬ ì˜ìƒì˜ ì œëª©ì„ ë‹´ì€ titlesì™€ URLì„ ë‹´ì€ urlsë¥¼ return í•¨

### ğŸ’» get_channel_video_url_list ğŸ’»
- ì›í•˜ëŠ” ì±„ë„ì— ëŒ€í•œ ìœ íŠœë¸Œ ì˜ìƒ ì œëª©ê³¼ URL ì„ Crawling í•˜ëŠ” í•¨ìˆ˜
- ì—¬ëŸ¬ ì˜ìƒì˜ ì œëª©ì„ ë‹´ì€ titlesì™€ URLì„ ë‹´ì€ urlsë¥¼ return í•¨

### ğŸ’» crawl_youtube_page_html_sources(urls) ğŸ’»
- ì—¬ëŸ¬ ì˜ìƒì— ëŒ€í•œ urlì„ ë‹´ì€ urls ë¦¬ìŠ¤íŠ¸ë¥¼ ì¸ìë¡œ ë°›ìŒ
- ê° URL ë§ˆë‹¤ Seleniumìœ¼ë¡œ ì ‘ê·¼í•˜ì—¬ ëŒ“ê¸€ì´ ëª¨ë‘ ë¡œë”© ë  ìˆ˜ ìˆë„ë¡ ìŠ¤í¬ë¡¤ì„ ì‹œí–‰í•˜ê³ 
- ìŠ¤í¬ë¡¤ì´ ëë‚˜ë©´ HTML ì½”ë“œë¥¼ Crawlí•œ í›„ 
- ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ return í•¨

### ğŸ’» get_user_IDs_and_comments(url_dict, video_type, html_source) ğŸ’»
- urlê³¼ ì œëª©ì´ ë‹´ê¸´ dictionary ê·¸ë¦¬ê³  HTML ì†ŒìŠ¤ì½”ë“œì™€ ë¹„ë””ì˜¤ íƒ€ì… (ì¼ë°˜ì˜ìƒ:watch / ì‡¼ì¸ ì˜ìƒ:shorts) ì¸ìë¡œ ë°›ìŒ
- ê° í˜ì´ì§€ ì†ŒìŠ¤ì½”ë“œì—ì„œ ëŒ“ê¸€ ë°ì´í„° ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê³ 
- ë¦¬ë·° ë°ì´í„°ì—ì„œ IDê°’ê³¼ ëŒ“ê¸€ ë¶€ë¶„ì„ ì¶”ì¶œí•œ í›„
- í˜ì´ì§€ ë³„ë¡œ ì¶”ì¶œ ê²°ê³¼ë¥¼ dictionary í˜•íƒœë¡œ ë§Œë“  ë’¤ return

### ğŸ’» convert_crawl_result_dict_to_csv(crawl_result_dict) ğŸ’»
- ì˜ìƒì˜ ì œëª©ê³¼ url ê·¸ë¦¬ê³  ì¶”ì¶œ ê²°ê³¼ê°€ ë‹´ê¸´ dictionary ë¥¼ ì¸ìë¡œ ë°›ìŒ
- ì¶”ì¶œê²°ê³¼ë¥¼ DataFrame í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì¤Œ
- titlesì˜ ì œëª©ë“¤ì—ì„œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•œ ì œëª©ì„ csv íŒŒì¼ì˜ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬
- ê°ê°ì˜ dataframeì„ to_csv ë¥¼ í™œìš©í•´ csvíŒŒì¼ë¡œ ì €ì¥í•¨


### ğŸ¤© ì½”ë“œ ì‚¬ìš© ì˜ˆì‹œ
#### ì˜ˆì‹œ 1 - í‚¤ì›Œë“œ ê²€ìƒ‰ > ë™ì˜ìƒ ëª©ë¡ url í¬ë¡¤ë§ > ê° ì˜ìƒë³„ ê²°ê³¼ dictionary ìƒì„± > dic to csv ì €ì¥
```Python3
crawling_result_list = []

titles, urls = get_urls_from_youtube_with_keyword(
    keyword = "ë ˆê³ "
)


watch_url, shorts_url = divide_watch_shorts(titles, urls)

watch_url = watch_url[:1]

# watch_url
html_sources = crawl_youtube_page_html_sources(watch_url)

for url_dict, html_source in zip(watch_url, html_sources):
    crawl_result = get_user_IDs_and_comments(
        url_dict=url_dict, 
        video_type="watch", 
        html_source=html_source
    )
    
    crawling_result_list.append(crawl_result)


for crawl_result in crawling_result_list:
    convert_crawl_result_dict_to_csv(
        crawl_result_dict=crawl_result
    )
```

#### ì˜ˆì‹œ 2 - ì±„ë„ ì´ë™ > ë™ì˜ìƒ ëª©ë¡ url í¬ë¡¤ë§ > ê° ì˜ìƒë³„ ê²°ê³¼ dictionary ìƒì„± > dic to csv ì €ì¥
```Python3
crawling_result_list = []

titles, urls = get_urls_from_youtube_with_keyword(
    keyword = "ë ˆê³ "
)


watch_url, shorts_url = divide_watch_shorts(titles, urls)

watch_url = watch_url[:1]

# watch_url
html_sources = crawl_youtube_page_html_sources(watch_url)

for url_dict, html_source in zip(watch_url, html_sources):
    crawl_result = get_user_IDs_and_comments(
        url_dict=url_dict, 
        video_type="watch", 
        html_source=html_source
    )
    
    crawling_result_list.append(crawl_result)


for crawl_result in crawling_result_list:
    convert_crawl_result_dict_to_csv(
        crawl_result_dict=crawl_result
    )
```

#### ì˜ˆì‹œ 3 - ì±„ë„ ì´ë™ > ë™ì˜ìƒ ëª©ë¡ url í¬ë¡¤ë§ > ê° ì˜ìƒë³„ ê²°ê³¼ dictionary ìƒì„± > dic to csv ì €ì¥
```Python3
crawling_result_list = []

titles, urls = get_channel_video_url_list(
    channel_url="https://www.youtube.com/c/%EA%BE%B8%EC%82%90KUPI/videos"
)


watch_url, shorts_url = divide_watch_shorts(titles, urls)

watch_url = watch_url[:1]

# watch_url
html_sources = crawl_youtube_page_html_sources(watch_url)

for url_dict, html_source in zip(watch_url, html_sources):
    crawl_result = get_user_IDs_and_comments(
        url_dict=url_dict, 
        video_type="watch", 
        html_source=html_source
    )
    
    crawling_result_list.append(crawl_result)


for crawl_result in crawling_result_list:
    convert_crawl_result_dict_to_csv(
        crawl_result_dict=crawl_result
    )
```
